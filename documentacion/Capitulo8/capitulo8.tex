%?????????????????????????
% Nombre: capitulo8.tex  
% 
% Texto del capitulo 8
%---------------------------------------------------

\chapter{Minería de datos: Reglas de asociación}
\label{minería}

En este capítulo nos centramos en la última etapa del modelo que vimos en el gráfico \ref{flujo}, donde por medio de técnicas de minería de datos basadas en el uso de las reglas de asociación trataremos de obtener información implícita en los datos y que sirva bien de apoyo o bien para corroborar, las ideas o premisas que hemos obtenido de nuestro proceso de análisis exploratorio de datos. 

Para la obtención de reglas se usarán dos algoritmos, el \textbf{Apriori} y el \textbf{FP-Growth}, con el fin de poder contrastar información y realizar una comparativa entre los resultados ofrecidos por ambos. Se estudiarán por tanto al inicio de capítulo los detalles de cada uno de los algoritmos.  Al finalizar el capítulo se verán distintas técnicas de visualización de las reglas obtenidas en el proceso experimental, así como la interpretación de las mismas. 

\section{Algoritmos usados}

En esta sección veremos una introducción teórica  a los algoritmos empleados en el proceso experimental. Dado que el objetivo del trabajo no está ligado al rendimiento o mejora de los mismos sino a los resultados sobre el dominio del problema, no entraremos en detalle en los mismos sino que se mencionará la idea subyacente de su funcionamiento para facilitar la comprensión de los puntos siguientes.

\subsection{Apriori}

El algoritmo \textbf{Apriori}, fue propuesto por Agrawal y Srikant en 1994 \cite{apriori} y desde entonces sigue siendo el algoritmo más extendido para la obtención de itemsets frecuentes, con los que construiremos en una segunda etapa las reglas de asociación. Se basa en el principio de que si un itemset es frecuente, entonces todos sus subconjuntos también lo son por lo que al encontrar uno de estos, podremos podar el árbol de búsqueda evitando hacer comprobaciones y aumentando la eficiencia. Para obtener los itemsets frecuentes, el algoritmo en base a un valor mínimo de soporte fijado por el experto en la materia, generará todas las posibles combinaciones de itemsets y comprobará si son o no frecuentes. En cada iteración, se generan todos los posibles itemsets distintos que se pueden formar combinando los de la anterior, por lo que los itemsets irán creciendo de tamaño.

Apriori tiene bastantes factores o limitaciones relacionados con la eficiencia del algoritmo y que pueden afectar en gran medida al proceso de minería de datos que en algunos problemas específicos podría incluso resultar prohibitivo por tiempos o espacio. Algunas de estas limitaciones serían:

\begin{enumerate}
\item Soporte: Umbrales demasiado bajos conllevarán a una explosión del número de itemsets frecuentes lo que está directamente relacionado con una mayor necesidad de memoria y tiempo. 
\item Número de ítems distintos: Esta limitación, está ligada a la necesidad del algoritmo apriori de almacenar el soporte de cada uno de éstos, lo que puede conllevar problemas de memoria. 
\item Tamaño de la base de datos: Este punto está ligado, al anterior, pero en lugar de tener en cuenta los ítems individuales se tienen en cuenta el número de transacciones. Apriori al ser exhaustivo realiza múltiples pasadas por toda la base de datos por lo que el tiempo de ejecución puede ser muy elevado o incluso no llegar a acabar en varios días o semanas. 
\item Longitud de las transacciones: Ligado al problema anterior, si las transacciones a su vez están formadas por muchos ítems, almacenar esto en memoria puede llegar a ser privativo e incluso imposible. 
\end{enumerate}

Estas limitaciones, nos han llevado a el estudio de otro método menos sensible a los requisitos temporales o de espacio, de cara a las posibles ampliaciones del problema a mayores cantidades de datos aún. Este método es el algoritmo FP-Growth y lo estudiaremos en el siguiente punto.

\subsection{FP-Growth}

El algoritmo \textbf{FP-Growth} \cite{fpg} fue propuesto en el año 2000, como una solución a los problemas de memoria generados por los métodos típicos como el Apriori, visto anteriormente. Es un algoritmo muy eficiente y ampliamente extendido en problemas y soluciones que podrían ser enmarcados bajo el nombre de Big Data. 

\textbf{FP-Growth}, crea un modelo comprimido de la base datos original utilizando una estructura de datos que denomina como \textbf{\textit{FP-tree}} que está formada por dos elementos esenciales:

\begin{itemize}
\item Grafo de transacciones: Gracias a este grafo la base de datos completa puede abreviarse. En cada nodo, se describe un itemsets y su soporte que se calcula siguiendo el camino que va desde la raiz hasta el nodo en cuestión.
\item Tabla cabecera: Es una tabla de listas de ítems. Es decir, para cada ítem, se crea una lista que enlaza nodos del grafo donde aparece. 
\end{itemize}

Una vez se construye el árbol, utilizando un enfoque recursivo basado en divide y vencerás, se extraen los itemsets frecuentes. Para ello primero se obtienen el soporte de cada uno de los ítems que aparecen en la tabla de cabecera, tras lo cual, para cada uno de los ítems que superan el soporte mínimo se realizan los siguientes pasos:

\begin{enumerate}
\item Se extrae la sección del árbol donde aparece el ítem reajustando los valores de soporte de los ítems que aparecen en esa sección.
\item Considerando esa sección extraída, se crea un nuevo \textbf{\textit{FP-tree}}.
\item Se extraen los itemsets que superen el mínimo soporte de este último \textbf{\textit{FP-tree}} creado. 
\end{enumerate}

En función a lo estudiado, es obvio ver que la memoria que ocupa es mucho menor que la generada por Apriori, así como al generar itemsets por medio del principio divide y vencerás, \textbf{FP-Growth} se presta a ser usado en entornos distribuidos como por ejemplo el entorno de Big Data, Apache Spark, aumentando sus prestaciones de manera notable. 

\section{Proceso experimental}

\subsection{Comparativa de rendimiento de ambos algoritmos}

\section{Visualización de reglas}

\section{Interpretación de las reglas}


%\begin{figure}[h]
%\centering
%\includegraphics[width=15cm]{./Capitulo5/imagenes/tuit.png}
%\caption{Ejemplo de un tuit.}
%\label{tuit}
%\end{figure}

\pagebreak
\clearpage
%---------------------------------------------------