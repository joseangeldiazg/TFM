%?????????????????????????
% Nombre: capitulo8.tex  
% 
% Texto del capitulo 8
%---------------------------------------------------

\chapter{Minería de datos}
\label{minería}

En este capítulo nos centramos en la última etapa del modelo que vimos en el gráfico \ref{flujo}, donde por medio de técnicas de minería de datos basadas en el uso de las reglas de asociación y análisis de sentimientos trataremos de obtener información implícita en los datos y que sirva bien de apoyo o bien para corroborar, las ideas o premisas que hemos obtenido de procesos anteriores. 

\section{Análisis de sentimientos}

Como vimos al comienzo de este capítulo, la motivación para realizar análisis de sentimientos es el tener la posibilidad de polarizar las reglas de asociación que obtendremos en la siguiente etapa en función de los términos que aparezcan en el antecedente o consecuente de las mismas. R ofrece una gran cantidad de paquetes para el análisis de sentimientos, en este trabajo se ha usado concretamente el paquete \textit{\textbf{syuzhet}}, que usa en su capa inferior el coreNLP de la Universidad de Standford \cite{nlp}.

Este paquete, contiene diccionarios muy potentes para la identificación de sentimientos y permite obtener estos por distintas técnicas y algoritmos en función de lo que se pase como argumento a la función \textit{get\_sentiments()}. Otro factor muy interesante del paquete es la posibilidad de obtener gráficos de cómo evolucionan los sentimientos en un texto, por ejemplo, los personajes de un libro empiezan tristes y acaban felices o viceversa. Dado nuestro problema donde en ningún caso podríamos considerar un tuit, como la continuación del otro, o que exista relación alguna entre ellos, esta funcionalidad carece de uso, y tendremos que fijarnos solo en los conteos de sentimientos y las palabras asociadas a cada uno de ellos. 

\subsection{Distribución de sentimientos en Twitter}

Al igual que hicimos para obtener las frecuencias de las palabras más usadas, obtendremos las frecuencias de los sentimientos para hacernos una idea del sentimiento de los americanos en Twitter en la primera mitad del año 2016. 

\begin{figure}[h]
\centering
\includegraphics[width=12cm]{./Capitulo8/imagenes/histsent.png}
\caption{Histograma de los sentimientos.}
\label{histsent}
\end{figure}

El histograma realizado puede verse en el gráfico \ref{histsent}, donde parece que  un número muy elevado de tuits hablan de \textbf{veracidad o afirmaciones}. Esto es normal ya que en Twitter mucha gente afirma hechos o noticias por lo que era de esperar que este sentimiento fuera el mayoritario. Por otro lado,  vemos que la \textbf{diversión} o el agrado tiene también una gran representación. Del mismo modo ocurre con la \textbf{anticipación}, este último debe ser analizado para ver que términos se asocian con anticipación, ya que es ambiguo. El resto de los sentimientos están más o menos equilibrados y frente a lo que cabría esperar de encontrarnos una sociedad enfadada o molesta parece que estos sentimientos están por detrás de otros más amables. 

\subsection{Palabras asociadas a los sentimientos}

El punto anterior nos informa del número de sentimientos de cada tipo, muy útil para ver la polaridad o el `estado de ánimo' del pueblo americano durante aquellas fechas, pero de cara a la obtención de qué palabras representan qué sentimientos, usaremos una nube de palabras, similar a las vistas anteriormente, pero categorizadas por colores en función de los sentimientos. El resultado de este gráfico podemos verlo en la figura \ref{cloudsent}.

\begin{figure}[h]
\centering
\includegraphics[width=7cm]{./Capitulo8/imagenes/cloudsent.png}
\caption{Palabras asociadas a los sentimientos.}
\label{cloudsent}
\end{figure}

Si entramos en el análisis del mismo, queda bastante más claro los datos con los que estamos trabajando y cómo se han polarizado los sentimientos. Vemos que trump, suscita sorpresa y que es la palabra más usada dentro de esta categoría. El sentimiento anticipación parece focalizarse en tiempos, y momentos temporales. Además hay cosas interesantes como relacionar \textbf{enfado} con los políticos, los asesinatos o la piratería entre otros casos. 

Un sentimiento muy interesante es el miedo, donde vemos un claro ejemplo de la sociedad americana. Vemos que la policía o el ejercito suscitan miedo, pero también aparece la palabra \textbf{transgénero}, bien sabido es la homofobia del país que tenemos entre manos, por lo que parece que nuestro proceso ha funcionado bastante bien. 

\section{Reglas de asociación}

Para la obtención de reglas se usarán dos algoritmos, el \textbf{Apriori} (proveniente del paquete arules de R) y el \textbf{FP-Growth} (proveniente del paquete Rspark) con el fin de poder contrastar información y realizar una comparativa entre los resultados ofrecidos por ambos. Se estudiarán por tanto al inicio del capítulo los detalles de cada uno de los algoritmos.  Al finalizar esta sección se verán distintas técnicas de visualización de las reglas obtenidas en el proceso experimental, así como la interpretación de las mismas. 

\subsection{Algoritmos usados}

En esta sección veremos una introducción teórica  a los algoritmos empleados en el proceso experimental. Dado que el objetivo del trabajo no está ligado al rendimiento o mejora de los mismos sino a los resultados sobre el dominio del problema, no entraremos en detalle en los mismos sino que se mencionará la idea subyacente de su funcionamiento para facilitar la comprensión de los puntos siguientes.

\subsubsection{Apriori}

El algoritmo \textbf{Apriori}, fue propuesto por Agrawal y Srikant en 1994 \cite{apriori} y desde entonces sigue siendo el algoritmo más extendido para la obtención de itemsets frecuentes, con los que construiremos en una segunda etapa las reglas de asociación. Se basa en el principio de que si un itemset es frecuente, entonces todos sus subconjuntos también lo son por lo que al encontrar uno de estos, podremos podar el árbol de búsqueda evitando hacer comprobaciones y aumentando la eficiencia. Para obtener los itemsets frecuentes, el algoritmo en base a un valor mínimo de soporte fijado por el experto en la materia, generará todas las posibles combinaciones de itemsets y comprobará si son o no frecuentes. En cada iteración, se generan todos los posibles itemsets distintos que se pueden formar combinando los de la anterior, por lo que los itemsets irán creciendo de tamaño.

Apriori tiene bastantes factores o limitaciones relacionados con la eficiencia del algoritmo y que pueden afectar en gran medida al proceso de minería de datos que en algunos problemas específicos podría incluso resultar prohibitivo por tiempos o espacio. Algunas de estas limitaciones serían:

\begin{enumerate}
\item Soporte: Umbrales demasiado bajos conllevarán a una explosión del número de itemsets frecuentes lo que está directamente relacionado con una mayor necesidad de memoria y tiempo. 
\item Número de ítems distintos: Esta limitación, está ligada a la necesidad del algoritmo apriori de almacenar el soporte de cada uno de éstos, lo que puede conllevar problemas de memoria. 
\item Tamaño de la base de datos: Este punto está ligado, al anterior, pero en lugar de tener en cuenta los ítems individuales se tienen en cuenta el número de transacciones. Apriori al ser exhaustivo realiza múltiples pasadas por toda la base de datos por lo que el tiempo de ejecución puede ser muy elevado o incluso no llegar a acabar en varios días o semanas. 
\item Longitud de las transacciones: Ligado al problema anterior, si las transacciones a su vez están formadas por muchos ítems, almacenar esto en memoria puede llegar a ser privativo e incluso imposible. 
\end{enumerate}

Estas limitaciones, nos han llevado a el estudio de otro método menos sensible a los requisitos temporales o de espacio, de cara a las posibles ampliaciones del problema a mayores cantidades de datos aún. Este método es el algoritmo FP-Growth y lo estudiaremos en el siguiente punto.

\subsubsection{FP-Growth}

El algoritmo \textbf{FP-Growth} \cite{fpg} fue propuesto en el año 2000, como una solución a los problemas de memoria generados por los métodos típicos como el Apriori, visto anteriormente. Es un algoritmo muy eficiente y ampliamente extendido en problemas y soluciones que podrían ser enmarcados bajo el nombre de Big Data. 

\textbf{FP-Growth}, crea un modelo comprimido de la base datos original utilizando una estructura de datos que denomina como \textbf{\textit{FP-tree}} que está formada por dos elementos esenciales:

\begin{itemize}
\item Grafo de transacciones: Gracias a este grafo la base de datos completa puede abreviarse. En cada nodo, se describe un itemset y su soporte que se calcula siguiendo el camino que va desde la raíz hasta el nodo en cuestión.
\item Tabla cabecera: Es una tabla de listas de ítems. Es decir, para cada ítem, se crea una lista que enlaza nodos del grafo donde aparece. 
\end{itemize}

Una vez se construye el árbol, utilizando un enfoque recursivo basado en divide y vencerás, se extraen los itemsets frecuentes. Para ello primero se obtienen el soporte de cada uno de los ítems que aparecen en la tabla de cabecera, tras lo cual, para cada uno de los ítems que superan el soporte mínimo se realizan los siguientes pasos:

\begin{enumerate}
\item Se extrae la sección del árbol donde aparece el ítem reajustando los valores de soporte de los ítems que aparecen en esa sección.
\item Considerando esa sección extraída, se crea un nuevo \textbf{\textit{FP-tree}}.
\item Se extraen los itemsets que superen el mínimo soporte de este último \textbf{\textit{FP-tree}} creado. 
\end{enumerate}

En función a lo estudiado, es obvio ver que la memoria que ocupa es mucho menor que la generada por Apriori, así como al generar itemsets por medio del principio divide y vencerás, \textbf{FP-Growth} se presta a ser usado en entornos distribuidos como por ejemplo el entorno de Big Data, Apache Spark, aumentando sus prestaciones de manera notable. Explotando este beneficio hemos hecho uso del algoritmo FP-Growth presente en el paquete RSpark, el cual  viene optimizado para una ejecución distribuida en entornos de Big Data. 

\subsection{Comparativa entre algoritmos}
\label{comparativa}
Antes de entrar a indagar en las reglas obtenidas y su interpretación, se presenta interesante la realización de una comparativa de rendimiento entre los dos algoritmos usados. Para la comparación se han usado tres valores de soporte (0.01, 0.001 y 0.001) y un valor de confianza estático de 0.7. La idea es comprar el comportamiento de los algoritmos y su capacidad para lidiar con un conjunto de reglas que aumenta en función de como disminuimos el valor del soporte. 

La elección de estos valores de soporte no es trivial ni aleatoria. Su justificación reside en la premisa de que los datos obtenidos representan una muestra aleatoria, por lo que si encontramos reglas con valores de soporte entre el 0.1\% y el 1\% en una `sección' de Twitter de 140000 tuits, y esto lo extrapolamos a la totalidad de Twitter, ese 1\% representaría una cantidad ingente de tuits, que podrían ser considerados como tendencia. 

Los parámetros que estudiaremos son aquellos más ligados al rendimiento, concretamente, el tiempo tomado en obtener las reglas, la memoria ocupada por las mismas y el número de reglas obtenidas. Acorde a estos parámetros los resultados obtenidos pueden verse en la tabla \ref{apriorires} para el algoritmo Apriori, y en la tabla \ref{fpres} para el algoritmo FP-Growth.

\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{APRIORI}   & \textbf{0,01 SUPP} & \textbf{0,001 SUPP} & \textbf{0,0001 SUPP} \\ \hline
\textit{TIEMPO}    & 1s 344ms           & 1s 490ms            & 10s 509ms            \\ \hline
\textit{MEMORIA}   & 16,7MB             & 18,8MB              & 209MB                \\ \hline
\textit{Nº REGLAS} & 5                  & 34119               & 2903429              \\ \hline
\end{tabular}%
}
\caption{Resultados para el algoritmo Apriori}
\label{apriorires}
\end{table}


\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{FP-GROWTH}   & \textbf{0,01 SUPP} & \textbf{0,001 SUPP} & \textbf{0,0001 SUPP} \\ \hline
\textit{TIEMPO}    & 6s 883ms           & 5s 992ms            & 3s 333ms             \\ \hline
\textit{MEMORIA}   & 0,00896MB          & 24,42MB             & 3,5GB                \\ \hline
\textit{Nº REGLAS} & 20                 & 34231               & 3764562              \\ \hline
\end{tabular}%
}
\caption{Resultados para el algoritmo FP-Growth}
\label{fpres}
\end{table}

Si estudiamos los resultados, vemos como la progresión de tiempo es mucho menor en el algoritmo FP-Growth, donde aunque no se muestran en la tabla, incluso hemos llegado a obtener reglas con soportes del orden de 0.000001 en pocos segundos, Apriori, en estos niveles provocaba la caída de R por lo que fueron obviados de los experimentos para tener datos concluyentes de ambos. Es necesario mencionar, que al tratarse de un enfoque distribuido, el proceso FP-Growth tendrá algunos segundos más en ciertos experimentos debido al tiempo que tarda en distribuir los datos para su posterior computo. 

Si nos fijamos en las reglas generadas, FP Growth, obtiene más que Apriori, aunque la progresión es muy similar. En cuanto al uso de memoria, cabe esperar un comportamiento anómalo de R a la hora de obtener los datos de Spark, ya que el tamaño del objeto para almacenar las últimas reglas es de 3,5GB, por lo que podríamos concluir que R no está haciendo una buena gestión de este tipo de datos y consume más memoria de la que debería. De igual modo, queda constatada la potencia del algoritmo FP-Growth para obtener reglas de asociación en grandes bases de datos. 

\subsection{Obtención de reglas}

En esta sección vamos a estudiar el proceso de obtención de reglas, así como las interpretaciones de las mismas. Pese a que nuestro proceso de selección de instancias ha conseguido reducir bastante el dataset, como hemos visto anteriormente, este aún puede conllevar a problemas de tiempo o espacio, por tanto, antes de comenzar a obtener reglas de asociación se han obtenido itemsets maximales, y cerrados para poder recuperar las reglas de manera eficiente y sin tantos requisitos de memoria. Para ilustrar la reducción de espacio, en el gráfico \ref{cerrados} podemos ver una comparativa entre los conjuntos generados para cada tipo, sin olvidar que podremos generar las mismas reglas  tanto si usamos los cerrados o maximales, como si usamos los frecuentes, con el consiguiente ahorro si nos decantamos por los primeros. 

\begin{figure}[h]
\centering
\includegraphics[width=11cm]{./Capitulo8/imagenes/cerrados.png}
\caption{Proporción de itemsets cerrados, maximales y frecuentes.}
\label{cerrados}
\end{figure}

Una vez en este punto usaremos el algoritmo Apriori, ya que dispone de más funcionalidad implementada en R que el FP-Growth, para obtener e interpretar las mejores reglas. Por los motivos explicados en la sección \ref{comparativa}, usaremos un mínimo soporte de 0.0001 y una confianza de al menos 0.7 para estudiar las reglas, que una vez obtenidas ordenaremos por orden descendente de soporte y confianza para poder estudiar las que el algoritmo considera como mejores. 

En la tabla \ref{reglasmalas} podemos ver algunas de las mejores reglas de asociación obtenidas según los parámetros de soporte y confianza. Estas reglas poco dicen y carecen de interés ninguno para la detección de tendencias sobre personas sino que nos caracterizan las tendencias de aplicaciones y usos de Twitter, como dar like a videos de \textbf{Youtube}, además de desvelarnos algunas páginas web o aplicaciones muy usadas como \textbf{Runtastic}, una aplicación para practicar deporte o \textbf{Transponder Snails} un juego social.

\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{ANTECEDENTE}     & \textbf{CONSECUENTE}                   & \textbf{SOPORTE} & \textbf{CONFIANZA} & \textbf{LIFT} \\ \hline
\textit{\{liked\}}       & \textit{=\textgreater \{youtube\}}     & 0.010410893      & 0.9071207          & 39.00037      \\ \hline
\textit{\{liked,video\}} & \textit{=\textgreater \{youtube\}}     & 0.010368254      & 0.9979480          & 42.90536      \\ \hline
\textit{\{snail\}}       & \textit{=\textgreater \{transponder\}} & 0.004789721      & 0.9955687          & 207.85524     \\ \hline
\textit{\{added\}}       & \textit{=\textgreater \{playlist\}}    & 0.003695334      & 0.8000000          & 192.76438     \\ \hline
\textit{\{runtastic\}}   & \textit{=\textgreater \{tracking\}}    & 0.0001350218     & 1                  & 4539.29032    \\ \hline
\end{tabular}%
}
\caption{Mejores reglas sin filtrado.}
\label{reglasmalas}
\end{table}

Acorde a los resultados, podríamos definir ciertas tendencias en cuanto a la sociedad estudiada como, que practican deporte o usan Youtube para escuchar música frente a otros medios. Aún así, estos resultados no son buenos y si queremos obtener información y tendencias sobre personas se ve necesario un proceso de filtrado de las reglas por consecuentes o antecedentes que puedan resultar interesantes. Nos centraremos por tanto en aquellas que contengan nombres que nuestro proceso de análisis exploratorio nos desveló como relevantes. 

\subsection{Filtrado de reglas}

Para la obtención de mejores resultados, filtraremos las reglas por el consecuente o antecedente en función de nombres propios que hemos obtenido de nuestro proceso de análisis exploratorio de datos. Dado que  el período de tiempo en el que nos centramos coincide con la campaña electoral de EEUU, nos hemos decantado por obtener las reglas generadas con consecuente igual a \textbf{donald-trump} o \textbf{hillary-clinton}. Sería imposible realizar un estudio acorde para un proyecto de estas características de todas las reglas generadas para nombres propios en Twitter en este período, por ello se han cogido estas dos a modo de ejemplo, pero es necesario señalar que el mismo estudio se podría aplicar sobre otros nombres, que no tendrían ni porqué pertenecer al mundo de la política. 

Por tanto, filtraremos las reglas donde el consecuente es \textbf{donald-trump} o \textbf{hillary-clinton} y eliminaremos las reglas redundantes. Al finalizar este proceso, tendremos un conjunto de 156 reglas para Donald Trump y un conjunto de 93 reglas para Hillary Clinton. Dado el número de estas, en las siguientes sub-secciones estudiaremos, visualizaremos e interpretaremos algunas de las más interesantes  que el proceso ha obtenido. 

\subsubsection{Donald Trump}

Como hemos mencionado anteriormente, para \textbf{Donald Trump} se ha generado un conjunto de 156 reglas cuya distribución en función de soporte, confianza y número de ítems en la regla puede verse en el gráfico \ref{distrump}. Atendiendo a este gráfico, podemos ver cómo la práctica totalidad de las reglas se sitúan en la parte izquierda lo que nos indica que los valores de soporte son más bien bajos aunque aceptables en función de la cantidad de datos con los que está formada la muestra. Por otro lado la confianza se distribuye normalmente y  la práctica totalidad de las reglas están formadas por tres o cuatro ítems. 

\begin{figure}[h]
\centering
\includegraphics[width=13cm]{./Capitulo8/imagenes/distrump.png}
\caption{Distribución de reglas para Donald Trump.}
\label{distrump}
\end{figure}

El gráfico anterior es útil para ver qué tipo de reglas hemos generado, pero será necesario estudiar estas reglas de manera manual y discernir sobre su importancia o no en el objetivo buscado de obtención de tendencias. Tras su estudio, algunas reglas interesantes obtenidas sobre \textbf{Donald Trump} pueden ser las que vemos en la tabla \ref{reglastrump}.

\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{ANTECEDENTE} & \textbf{CONSECUENTE} & \textbf{SOPORTE} & \textbf{CONFIANZA} & \textbf{LIFT} \\ \hline
\textit{\{military,people,transgender\}} & \textit{=\textgreater \{donald-trump\}} & 3.553206e-04 & 0.7142857 & 68.79730 \\ \hline
\textit{\{military,serve,transgender\}} & \textit{=\textgreater \{donald-trump\}} & 1.918731e-04 & 0.7941176 & 76.48641 \\ \hline
\textit{\{bans,serving, transgender\}} & \textit{=\textgreater \{donald-trump\}} & 8.527694e-05 & 0.9230769 & 88.90728 \\ \hline
\textit{\{ignored,rape\}} & \textit{=\textgreater \{donald-trump\}} & 9.948976e-05 & 1 & 96.31622 \\ \hline
\textit{\{child,rape\}} & \textit{=\textgreater \{donald-trump\}} & 9.948976e-05 & 0.9333333 & 89.89514 \\ \hline
\textit{\{caucus,lead\}} & \textit{=\textgreater \{donald-trump\}} & 8.527694e-05 & 0.8571429 & 82.55676 \\ \hline
\end{tabular}%
}
\caption{Reglas interesantes sobre Donald Trump.}
\label{reglastrump}
\end{table}

Fijándonos en la anterior tabla, las tres primeras reglas han sido seleccionadas para su análisis en grupo dado que hay bastantes más reglas que hablan de lo mismo. Podemos constatar una tendencia clara en cuanto a las políticas de Trump con las personas transgénero y su posibilidad de servir en el ejército de los Estados Unidos. Concretamente la regla \textit{\{ bans,serving, transgender\} =\textgreater \{donald-trump\}} nos deja entrever que el actual presidente tenía muy claro que prohibiría el servicio de estas personas en el ejército, algo que ya por 2016 se venía barajando y que fue confirmado en 2017.

Otra tendencia interesante puede ser marcada por las dos siguientes reglas, \textit{\{ ignored,rape\} =\textgreater \{donald-trump\} } y \textit{\{ child,rape\} =\textgreater \{donald-trump\}}, donde por medio de la minería de datos hemos obtenido una tendencia en Twitter durante la primera mitad del año 2016, donde el por aquel entonces candidato a ocupar la Casa Blanca, se vio involucrado en ciertos escándalos relacionados con violaciones o la no condena de estas.  Por último, encontramos también una regla interesante en \textit{\{ caucus,lead\} =\textgreater \{donald-trump\}}que nos constata el hecho comprobado de que todas las encuestas consideraban a este líder en intención de voto entre las personas de raza caucásica. 

Aunque su estudio manual es necesario puede llegar a ser tedioso. Por ello, resulta interesante disponer de medios de visualización que nos ayuden a hacernos una idea a grandes rasgos de las reglas generadas, más aún si el conjunto de las mismas es de gran tamaño. Para conseguir este objetivo está muy extendido el tipo de gráficos como el que podemos ver en la figura \ref{burbujas}, aunque tras su estudio y aplicación en nuestro problema, tal y como podemos ver este no es muy revelador. Por este motivo y dado que tratamos de representar y obtener tendencias en Twitter, en la figura \ref{cloudtrump} se ha obtenido una representación en forma de nube de palabras, que representa en función del tamaño las palabras más usadas en los antecedentes de las reglas que tienen como consecuente nuestro objetivo, en este caso \textbf{Donald Trump}. 

\begin{figure}[h]
\centering
\includegraphics[width=11cm]{./Capitulo8/imagenes/burbujas.png}
\caption{Grafo de las reglas para Donald Trump.}
\label{burbujas}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=11cm]{./Capitulo8/imagenes/cloudtrump.png}
\caption{Nube de palabras de las reglas para Donald Trump.}
\label{cloudtrump}
\end{figure}

Si atendemos por tanto a la representación de las reglas con nube de términos, hasta una persona sin conocimientos sobre la temática podría deducir de qué se está hablando en Twitter y cuáles son las tendencias en relación con el candidato. Por ejemplo encontramos las palabras \textit{transgender, rape, child } sobre las cuales anteriormente en nuestro proceso manual hemos podido obtener tendencias. También aparece \textit{Iowa} como relevante, una palabra que anteriormente en el proceso manual obviamos y que ahora gracias a este gráfico vemos que es interesante. Si volvemos a localizar manualmente las reglas con este ítem en el antecedente, veremos que este fue un estado decisivo y muy rivalizado durante las elecciones presidenciales, por lo que las encuestas y la opinión pública generaban continuamente información al respecto.  


\subsubsection{Hillary Clinton}

Para \textbf{Hillary Clinton} se han obtenido un total de 93 reglas de asociación. La distribución de las mismas, acorde a sus medidas de bondad puede verse en el gráfico \ref{dishillary}. Atendiendo al mismo, podemos ver como en este caso las reglas se sitúan a lo largo del eje X de manera más uniforme que como lo hacían en el gráfico \ref{distrump}, contando con un buen número de reglas en el borde derecho lo que nos indica buenos valores de soporte en las mismas. A diferencia de lo ocurrido con \textbf{Trump}, aquí casi todas las reglas implican 3 ítems, teniendo muy pocas de orden distinto a 3. 

\begin{figure}[h]
\centering
\includegraphics[width=13cm]{./Capitulo8/imagenes/dishillary.png}
\caption{Distribución de reglas para Hillary Clinton.}
\label{dishillary}
\end{figure}


Una vez definido el conjunto de reglas generado, estudiaremos manualmente el conjunto de las mismas para obtener información relevante sobre \textbf{Hillary Clinton} al igual que hicimos con \textbf{Trump}. Tras este análisis manual, realizaremos de nuevo un gráfico de nube de palabras para tratar de corroborar las tendencias halladas manualmente e incluso localizar alguna nueva que se pudiera haber pasado a nuestro proceso de interpretación de reglas.  Una vez estudiadas las mismas, podríamos acotar las reglas de la tabla \ref{reglashillary} como las más interesantes. 

\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{ANTECEDENTE} & \textbf{CONSECUENTE} & \textbf{SOPORTE} & \textbf{CONFIANZA} & \textbf{LIFT} \\ \hline
\textit{\{better,vote\}} & \textit{=\textgreater \{hillary-clinton\}} & 3.908526e-04 & 0.9016393 & 246.8422 \\ \hline
\textit{\{musician,squad\}} & \textit{=\textgreater \{hillary-clinton\}} & 3.837462e-04 & 1 & 273.7704 \\ \hline
\textit{\{musician,support\}} & \textit{=\textgreater \{hillary-clinton\}} & 3.837462e-04 & 1 & 88.90728 \\ \hline
\textit{\{bernie-sanders,vs\}} & \textit{=\textgreater \{hillary-clinton\}} & 3.837462e-04 & 1 & 273.7704 \\ \hline
\textit{\{bernie-sanders,better\}} & \textit{=\textgreater \{hillary-clinton\}} & 3.837462e-04 & 0.9473684 & 259.3615 \\ \hline
\textit{\{bernie-sanders,race\}} & \textit{=\textgreater \{hillary-clinton\}} & 2.202988e-04 & 0.9687500 & 265.2151 \\ \hline
\textit{\{emails,republicans\}} & \textit{=\textgreater \{hillary-clinton\}} & 1.563411e-04 & 1 & 273.7704 \\ \hline
\textit{\{attack,emails\}} & \textit{=\textgreater \{hillary-clinton\}} & 1.563411e-04 & 1 & 273.7704 \\ \hline
\textit{\{attack,republicans\}} & \textit{=\textgreater \{hillary-clinton\}} & 1.563411e-04 & 0.8800000 & 240.9180 \\ \hline
\end{tabular}%
}
\caption{Reglas interesantes sobre Hillary Clinton.}
\label{reglashillary}
\end{table}

Si realizamos un enfoque de interpretación por grupos, podríamos definir claramente tres tendencias y grupos de opiniones en los tuits relacionados con \textbf{Hillary Clinton} :

\begin{enumerate}
\item El compromiso del mundo del espectáculo con su candidatura: Las tres primeras reglas de la tabla, \textit{\{ better,vote\} =\textgreater \{hillary-clinton\}} , \textit{\{ musician,squad\} =\textgreater \{hillary-clinton\}} y \textit{\{ musician,support\} =\textgreater \{hillary-clinton\}}, hacen referencia al apoyo recibido por la candidata por parte de grandes estrellas del mundo del espectáculo que no tardaron en salir a defender su candidatura a la presidencia en grandes eventos públicos.  
\item La carrera con su competidor demócrata Bernie Sanders: Esta tendencia era clara, y es que antes de comenzar a analizar las reglas sabríamos que estas aparecerían ya que nuestro proceso de EDA desveló a Bernie Sanders como uno de los nombres más usados en Twitter en aquel período de tiempo. Las reglas \textit{\{ bernie-sanders,vs\} =\textgreater \{hillary-clinton\}} , \textit{\{ bernie-sanders,better\} =\textgreater \{hillary-clinton\}} y \textit{\{ bernie-sanders,race\} =\textgreater \{hillary-clinton\}}, constatan por tanto la tendencia en Twitter a discutir sobre quién de los dos merecía más el puesto de candidato  y sus políticas asociadas. 
\item El escándalo de los mails: Las tres últimas reglas, \textit{\{ emails,republicans\} =\textgreater \{ hillary-clinton \}} , \textit{\{ attack,republicans\} =\textgreater \{hillary-clinton\}} y \textit{\{attack,emails\} =\textgreater \{hillary-clinton\}}, hacen referencia a los mails filtrados de Hillary Clinton y al uso como ataque que los republicanos hicieron de los mismos. 
\end{enumerate}

Por último, corroboraremos nuestros resultados con la nube de palabras, donde podremos ahondar de manera sencilla en otras tendencias que \textit{a priori} podamos no haber tenido en cuenta. El gráfico elaborado puede verse en la figura \ref{cloudhillary} y en este caso constatamos la totalidad de las conclusiones obtenidas anteriormente, donde destacamos la importancia de la relación entre las opiniones de Bernie Sanders y la propia Hillary Clinton. Por otro lado, volvemos a ver Iowa, algo que ya cabría esperar desde el momento en que estudiamos la nube de términos de las reglas de \textbf{Trump}, ya que al ser un estado disputado entre ambos candidatos, las reglas relacionadas serán bidireccionales.  

\begin{figure}[h]
\centering
\includegraphics[width=11cm]{./Capitulo8/imagenes/cloudhillary.png}
\caption{Nube de palabras de las reglas para Hillary Clinton.}
\label{cloudhillary}
\end{figure}

\subsection{Interpretación jerárquica basada en sentimientos}

Las reglas de asociación pueden estudiarse e interpretarse desde un punto de vista jerárquico, es decir, en el ejemplo de cesta de la compra, la regla \textit{\{Manzanas, platanos\} => \{Yogurt\}} podría sustituirse por \textit{\{Fruta\} => \{Yogurt\}}. Esto nos permite un grado mayor de abstracción sobre los datos interesante de cara a obtener nueva información relevante. Dado que gracias a nuestro análisis de sentimientos tenemos polarizadas cada una de las palabras presentes en el dominio de nuestro problema vamos a jerarquizar estas reglas en función de los sentimientos que representan a cada palabra. Para ello, filtraremos los tuits que hacen referencia a los personajes que venimos estudiando en esta sección y cambiaremos las palabras de estos tuits por el sentimiento mayoritario asociado a cada una de ellas. Posteriormente, se vuelve a obtener las reglas de asociación sobre este conjunto de datos. Los resultados para \textbf{Donald Trump} pueden verse en la tabla \ref{jertrump} mientras que los resultados obtenidos para \textbf{Hillary Clinton} podemos verlos en la tabla \ref{jerhillary}.

\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{ANTECEDENTE}      & \textbf{CONSECUENTE}                    & \textbf{SOPORTE} & \textbf{CONFIANZA} & \textbf{LIFT} \\ \hline
\textit{\{trust\}}        & \textit{=\textgreater \{donald-trump\}} & 0.94592745       & 1                  & 1             \\ \hline
\textit{\{anticipation\}} & \textit{=\textgreater \{donald-trump\}} & 0.59411362       & 1                  & 1             \\ \hline
\textit{\{surprise\}}     & \textit{=\textgreater \{donald-trump\}} & 0.42505133       & 1                  & 1             \\ \hline
\textit{\{anger\}}        & \textit{=\textgreater \{donald-trump\}} & 0.34565366       & 1                  & 1             \\ \hline
\textit{\{fear\}}         & \textit{=\textgreater \{donald-trump\}} & 0.29500342       & 1                  & 1             \\ \hline
\textit{\{joy\}}          & \textit{=\textgreater \{donald-trump\}} & 0.22655715       & 1                  & 1             \\ \hline
\textit{\{disgust\}}      & \textit{=\textgreater \{donald-trump\}} & 0.11293634       & 1                  & 1             \\ \hline
\textit{\{sadness\}}      & \textit{=\textgreater \{donald-trump\}} & 0.07460643       & 1                  & 1             \\ \hline
\end{tabular}%
}
\caption{Reglas jerárquicas por sentimientos sobre Donald Trump}
\label{jertrump}
\end{table}


\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{ANTECEDENTE} & \textbf{CONSECUENTE} & \textbf{SOPORTE} & \textbf{CONFIANZA} & \textbf{LIFT} \\ \hline
\textit{\{trust\}} & \textit{=\textgreater \{hillary-clinton\}} & 0.93968872 & 1 & 1 \\ \hline
\textit{\{anger\}} & \textit{=\textgreater \{hillary-clinton\}} & 0.49221790 & 1 & 1 \\ \hline
\textit{\{anticipation\}} & \textit{=\textgreater  \{hillary-clinton\}} & 0.48638132 & 1 & 1 \\ \hline
\textit{\{fear\}} & \textit{=\textgreater \{hillary-clinton\}} & 0.29961089 & 1 & 1 \\ \hline
\textit{\{surprise\}} & \textit{=\textgreater \{hillary-clinton\}} & 0.20038911 & 1 & 1 \\ \hline
\textit{\{joy\}} & \textit{=\textgreater \{hillary-clinton\}} & 0.14591440 & 1 & 1 \\ \hline
\textit{\{sadness\}} & \textit{=\textgreater \{hillary-clinton\}} & 0.07976654 & 1 & 1 \\ \hline
\textit{\{disgust\}} & \textit{=\textgreater \{hillary-clinton\}} & 0.07782101 & 1 & 1 \\ \hline
\end{tabular}%
}
\caption{Reglas jerárquicas por sentimientos sobre Hillary Clinton}
\label{jerhillary}
\end{table}

Lo primero que resulta interesante de las reglas obtenidas, es que sin buscarlo hemos elaborado un ranking de los sentimientos que identifican a cada una de las personas estudiadas. Lo primero que sale a la vista y que podríamos concluir es que en Twitter se han emitido más tuits de apoyo y respaldo contra ambos candidatos que de otro tipo de sentimiento, esto podemos verlo ya que el sentimiento de certeza está presente en casi el 95\% de los tuits que hablan de ellos. 
Una interpretación muy interesante es la que podemos hacer del sentimiento \textbf{anger}, donde vemos cómo el 50\% de los tuits que hablan de Hillary Clinton, tienen a su vez relacionados este sentimiento, por contra, Trump, tiene un 20\% menos de este sentimiento, por lo que parece que la sociedad americana a pesar de lo que parecía estaba más en contra o enfadados con  Hillary Clinton que con Trump, algo que posteriormente se vio confirmado con la victoria de la candidatura del candidato republicano. También cabe destacar el sentimiento de sorpresa en Donald Trump, ya que es mundialmente conocido por sus arrebatos en redes sociales y políticas por lo que era de esperar que este sentimiento tuviera gran relevancia en los tuits que hablan del actual presidente de los Estados Unidos de América. 

\pagebreak
\clearpage
%---------------------------------------------------